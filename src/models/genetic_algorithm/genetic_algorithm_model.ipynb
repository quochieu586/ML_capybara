{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic algorithm\n",
    "\n",
    "- In this juptyer notebook, we apply `Genetic Algorithm` on fitting Neural Network model instead of using *gradient descent* to fit the model.\n",
    "    \n",
    "    + Each model is represented by a fixed-length list of parameters.\n",
    "\n",
    "    + A population of neural network models are initlized without further training.\n",
    "\n",
    "    + *Crossover* is performed as usual by swapping paramters between 2 models.\n",
    "\n",
    "    + *Mutation*, however, since it is string of float numbers (not bits) we can not do flipping as normal. Instead, we add a random noise with some probability to chosen parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries and define constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used device = mps\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add project root to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\")))\n",
    "\n",
    "from data import Preprocessing, FeatureExtraction\n",
    "\n",
    "# switch to device for better training\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Used device = {DEVICE}\")\n",
    "\n",
    "# define constant which can be treated hyperparameter\n",
    "MAX_FEATURES = 500\n",
    "POPULATION_SIZE = 10\n",
    "GENERATIONS = 100\n",
    "MUTATION_RATE = 0.2\n",
    "MUTATION_NOISE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file csv and print out necessary informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3534 entries, 0 to 3533\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   textID            3534 non-null   object \n",
      " 1   text              3534 non-null   object \n",
      " 2   sentiment         3534 non-null   object \n",
      " 3   Time of Tweet     3534 non-null   object \n",
      " 4   Age of User       3534 non-null   object \n",
      " 5   Country           3534 non-null   object \n",
      " 6   Population -2020  3534 non-null   float64\n",
      " 7   Land Area (Km²)   3534 non-null   float64\n",
      " 8   Density (P/Km²)   3534 non-null   float64\n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 276.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346.0</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797.0</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044.0</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272.0</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment  \\\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n",
       "3  01082688c6                                        happy bday!  positive   \n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n",
       "\n",
       "  Time of Tweet Age of User      Country  Population -2020  Land Area (Km²)  \\\n",
       "0       morning        0-20  Afghanistan        38928346.0         652860.0   \n",
       "1          noon       21-30      Albania         2877797.0          27400.0   \n",
       "2         night       31-45      Algeria        43851044.0        2381740.0   \n",
       "3       morning       46-60      Andorra           77265.0            470.0   \n",
       "4          noon       60-70       Angola        32866272.0        1246700.0   \n",
       "\n",
       "   Density (P/Km²)  \n",
       "0             60.0  \n",
       "1            105.0  \n",
       "2             18.0  \n",
       "3            164.0  \n",
       "4             26.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepro = Preprocessing()\n",
    "df = prepro.read_CSV()\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing step\n",
    "\n",
    "- Encoding the label\n",
    "\n",
    "- Applying some basics preprocessing technique on column `text` which is the main feature:\n",
    "\n",
    "    + **clean text**: remove unnecessary characters.\n",
    "\n",
    "    + **text lowercase**\n",
    "\n",
    "    + **remove punction**\n",
    "\n",
    "    + **remove stopword**\n",
    "\n",
    "    + **Lemmatize**\n",
    "\n",
    "- Tf-idf vectorizing for text on column `text`\n",
    "\n",
    "- Scale dataset to standard normal distribution using `StandardScaler` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3534, 500), (3534, 500))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert column `sentiment` to numerical label\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['sentiment'])\n",
    "\n",
    "# preprocessigng text column\n",
    "df['text'] = df['text'].apply(prepro.preprocess)\n",
    "\n",
    "# extract tf-idf vector\n",
    "feature_extraction = FeatureExtraction()\n",
    "tfidf_count = feature_extraction.tfidf_vectorize(df['text'], 2, max_features=MAX_FEATURES)\n",
    "df_tfidf_count = tfidf_count.toarray()\n",
    "\n",
    "# scale data to standard normal distribution\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(df_tfidf_count)\n",
    "\n",
    "tfidf_count.shape, df_tfidf_count.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset into training, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2827, 500), (353, 500), (354, 500), (2827,), (353,), (354,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = feature_extraction.split_dataset(df_tfidf_count, np.array(df['label'].to_list()))\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build neural model class\n",
    "\n",
    "- We try a simple neural network model with 2 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralModel(\n",
       "  (layer1): Linear(in_features=500, out_features=20, bias=True)\n",
       "  (layer2): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (layer3): Linear(in_features=10, out_features=3, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_1=20, hidden_layer_2=10):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features=input_size, out_features=hidden_layer_1)\n",
    "        self.layer2 = nn.Linear(in_features=hidden_layer_1, out_features=hidden_layer_2)\n",
    "        self.layer3 = nn.Linear(in_features=hidden_layer_2, out_features=3)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.layer1(x))\n",
    "        x = torch.sigmoid(self.layer2(x))\n",
    "        x = self.softmax(self.layer3(x))\n",
    "        return x\n",
    "\n",
    "model = NeuralModel(MAX_FEATURES)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some supported functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `encode_weights` for flattening model into list of parameters.\n",
    "\n",
    "- `decode_weights` for converting it back to normal neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_weights(model):\n",
    "    \"\"\"Flatten the weights of the model into a chromosome.\"\"\"\n",
    "    return torch.cat([p.view(-1) for p in model.parameters()])\n",
    "\n",
    "def decode_weights(model, weights):\n",
    "    \"\"\"Reshape a chromosome into model weights.\"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        index = 0\n",
    "\n",
    "        for param in model.parameters():\n",
    "            num_params = param.numel()\n",
    "            param.copy_(weights[index:index+num_params].view(param.shape))\n",
    "            index += num_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`initialize_population` initilizes a number of neural network and encodes their parameter into sequence of gens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_population(pop_size, input_size, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Intialize a population of neural networks\n",
    "    \"\"\"\n",
    "    population = []\n",
    "    for _ in range(pop_size):\n",
    "        new_model = NeuralModel(input_size).to(device)\n",
    "        weights = encode_weights(new_model) # convert model to sequence of gens\n",
    "        population.append(weights)\n",
    "    \n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Fitness_score` computes the accuracy of input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fitness(weights, model, X, y, batch_size=32):\n",
    "    decode_weights(model, weights)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        device = next(model.parameters()).device  # Get model's device\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            X_batch = torch.tensor(X[i:i+batch_size], dtype=torch.float32).to(device)\n",
    "            y_batch = torch.tensor(y[i:i+batch_size], dtype=torch.float32).to(device)\n",
    "\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            correct += (pred == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "# example usage\n",
    "X = np.array([np.array(range(MAX_FEATURES)), np.array(range(MAX_FEATURES, MAX_FEATURES*2)), np.array(range(MAX_FEATURES*2, MAX_FEATURES*3))])\n",
    "y = np.array([0,1,2])\n",
    "weights = encode_weights(model)\n",
    "fitness(weights, model, X, y, batch_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model_selection` shuffles and gets 2 models from population based on distributions generated by fitness scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D', 'D']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_selection(population, fitness_score, parents_size=2):\n",
    "    probabilities = fitness_score / (fitness_score.sum() + 1e-8)\n",
    "\n",
    "    indices = torch.multinomial(probabilities, num_samples=parents_size, replacement=True)\n",
    "\n",
    "    return [population[i] for i in indices.tolist()]\n",
    "\n",
    "population = ['A', 'B', 'C', 'D']  # Example elements\n",
    "fitness_score = torch.tensor([1.0, 2.0, 4.0, 5.0])\n",
    "\n",
    "n = 2  # Number of elements to sample\n",
    "model_selection(population, fitness_score, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`crossover` swaps random elements between 2 parents and returns their childrens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10, 11,  2, 13, 14, 15, 16,  7,  8, 19]),\n",
       " tensor([ 0,  1, 12,  3,  4,  5,  6, 17, 18,  9]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def crossover(parent_1, parent_2, device=\"cpu\"):\n",
    "    mask = torch.randint(low=0, high=2, size=(len(parent_1),), dtype=torch.bool).to(device)\n",
    "    child_1 = torch.where(mask, parent_1, parent_2)\n",
    "    child_2 = torch.where(mask, parent_2, parent_1)\n",
    "\n",
    "    return child_1, child_2\n",
    "\n",
    "# example\n",
    "list_A = torch.tensor(list(range(10)))\n",
    "list_B = torch.tensor(list(range(10,20)))\n",
    "\n",
    "crossover(list_A, list_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mutation` adds random noise to some parameter in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  1.0000,  2.0000,  3.0000,  4.0000,  5.0000,  6.0000,  7.0000,\n",
       "         8.0000,  9.0000, 10.0000, 11.0000, 12.0000, 13.0000, 14.0000, 15.0000,\n",
       "        16.0000, 17.0000, 18.3696, 19.0000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mutation(weights, mutation_rate=0.05, noise=0.1):\n",
    "    total_params = len(weights)\n",
    "    mutation_num = int(mutation_rate * total_params)\n",
    "    mutation_indices = np.random.randint(low=0, high=total_params, size=mutation_num)\n",
    "\n",
    "    for idx in mutation_indices:\n",
    "        weights[idx] += (2*torch.rand(1) - 1).squeeze()\n",
    "\n",
    "    return weights\n",
    "\n",
    "# example\n",
    "weights = torch.tensor(range(20), dtype=torch.float32)\n",
    "mutation(weights, mutation_rate=0.05, noise=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolving Generations: 100%|██████████| 100/100 [08:45<00:00,  5.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy on Test Set: 0.4040\n",
      "Final Accuracy on Train Set: 0.4040\n"
     ]
    }
   ],
   "source": [
    "# Genetic Algorithm Parameters\n",
    "population = initialize_population(POPULATION_SIZE, X_train.shape[1], device=DEVICE)\n",
    "model = NeuralModel(X_train.shape[1]).to(DEVICE)\n",
    "\n",
    "for generation in tqdm(range(GENERATIONS), desc=\"Evolving Generations\"):\n",
    "    # compute fitness scores of current population\n",
    "    fitness_scores = torch.tensor([fitness(weights, model, X_train, y_train, batch_size=10) for weights in population])\n",
    "\n",
    "    # Generate new population\n",
    "    new_population = []\n",
    "    for _ in range(POPULATION_SIZE // 2):\n",
    "        parents = model_selection(population, fitness_scores)\n",
    "        child1, child2 = crossover(parents[0], parents[1], device=DEVICE)\n",
    "        new_population.append(mutation(child1, mutation_rate=MUTATION_RATE, noise=MUTATION_NOISE))\n",
    "        new_population.append(mutation(child2, mutation_rate=MUTATION_RATE, noise=MUTATION_NOISE))\n",
    "\n",
    "    population = new_population\n",
    "\n",
    "best_weights = population[np.argmax(fitness_scores)]\n",
    "decode_weights(model, best_weights)\n",
    "final_acc = fitness(best_weights, model, X_test, y_test)\n",
    "train_acc = fitness(best_weights, model, X_train, y_train)\n",
    "\n",
    "print(f\"Final Accuracy on Test Set: {final_acc:.4f}\")\n",
    "print(f\"Final Accuracy on Train Set: {train_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation:\n",
    "\n",
    "- Confusion matrix\n",
    "\n",
    "- Accuracy\n",
    "\n",
    "- F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments on model\n",
    "\n",
    "- The model performs the poor result as it is underfitting (low accuracy on train set). This may be due to poor weights's update strategy. Crossover and mutation do not work well on improving model performance since we works on string of float numbers but not bits as usual. Hence the search space for hypothesis will be extremely larger, or exactly, be infinite.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Env_for_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
